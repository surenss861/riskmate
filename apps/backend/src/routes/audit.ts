import express from 'express'
import { supabase } from '../lib/supabaseClient'
import { authenticate, AuthenticatedRequest } from '../middleware/auth'
import { RequestWithId } from '../middleware/requestId'
import { createErrorResponse, logErrorForSupport } from '../utils/errorResponse'
import { recordAuditLog } from '../middleware/audit'
import { runCommand, CommandContext, CommandOptions, applyAuditFilters } from '../utils/commandRunner'
import archiver from 'archiver'
import { Readable } from 'stream'
import crypto from 'crypto'
// Event mapping utilities are used in frontend only
// Backend doesn't need these imports

export const auditRouter = express.Router()

// Helper: Generate Controls CSV as Buffer
async function generateControlsCSV(
  organizationId: string,
  userId: string,
  exportId: string,
  jobId?: string,
  siteId?: string,
  timeRange: string = '30d'
): Promise<{ buffer: Buffer; count: number }> {
  // Fetch jobs
  let jobsQuery = supabase
    .from('jobs')
    .select('id, client_name, risk_score, risk_level, status, site_name')
    .eq('organization_id', organizationId)
    .is('deleted_at', null)

  if (jobId) jobsQuery = jobsQuery.eq('id', jobId)
  if (siteId) jobsQuery = jobsQuery.eq('site_id', siteId)

  const { data: jobs } = await jobsQuery
  if (!jobs || jobs.length === 0) {
    throw new Error('No jobs found for controls export')
  }

  // Fetch mitigations
  const jobIds = jobs.map(j => j.id)
  const { data: mitigations } = await supabase
    .from('mitigation_items')
    .select('id, job_id, title, description, done, is_completed, created_at')
    .in('job_id', jobIds)

  // Group by job
  const controlsByJob = jobs.map(job => ({
    job_id: job.id,
    job_name: job.client_name,
    risk_score: job.risk_score,
    risk_level: job.risk_level,
    status: job.status,
    site_name: job.site_name,
    controls: (mitigations || []).filter(m => m.job_id === job.id).map(m => ({
      id: m.id,
      title: m.title,
      description: m.description,
      status: m.done || m.is_completed ? 'completed' : 'pending',
      created_at: m.created_at,
    })),
  }))

  // Note: Ledger entries are now fetched later with event_type

  // Get org and user data
  const { data: orgData } = await supabase
    .from('organizations')
    .select('name')
    .eq('id', organizationId)
    .single()

  const { data: userData } = await supabase
    .from('users')
    .select('full_name, role')
    .eq('id', userId)
    .single()

  const now = new Date().toISOString()
  const headerBlock = [
    'RiskMate Controls Report',
    `Export ID: ${exportId}`,
    `Generated: ${now}`,
    `Generated By: ${userData?.full_name || 'Unknown'} (${userData?.role || 'Unknown'})`,
    `Organization: ${orgData?.name || 'Unknown'}`,
    `Time Range: ${timeRange}`,
    `Work Records: ${jobs.length}`,
    `Total Controls: ${mitigations?.length || 0}`,
    `Completed: ${mitigations?.filter(m => m.done || m.is_completed).length || 0}`,
    `Pending: ${mitigations?.filter(m => !m.done && !m.is_completed).length || 0}`,
    '',
    '--- Controls Data ---',
  ]

  // Exact header order per schema specification
  const HEADERS = [
    'control_id',
    'ledger_entry_id',
    'ledger_event_type',
    'work_record_id',
    'site_id',
    'org_id',
    'status_at_export',
    'severity',
    'title',
    'owner_user_id',
    'owner_email',
    'due_date',
    'verification_method',
    'created_at',
    'updated_at',
  ]

  // Fetch additional data needed for schema
  const allControlIds = controlsByJob.flatMap(j => j.controls.map(c => c.id))
  const { data: controlsWithDetails } = await supabase
    .from('mitigation_items')
    .select('id, owner_id, due_date, verification_method, created_at, updated_at')
    .in('id', allControlIds)

  const controlDetailsMap = new Map(
    (controlsWithDetails || []).map(c => [c.id, c])
  )

  // Fetch owner emails
  const ownerIds = [...new Set((controlsWithDetails || []).map(c => c.owner_id).filter(Boolean))]
  const { data: owners } = await supabase
    .from('users')
    .select('id, email')
    .in('id', ownerIds)

  const ownerMap = new Map((owners || []).map(o => [o.id, o.email]))

  // Ledger entries already fetched above

  // Fetch ledger entries with event_type
  const { data: ledgerEntriesWithType } = await supabase
    .from('audit_logs')
    .select('target_id, id as ledger_entry_id, event_name as ledger_event_type')
    .in('target_id', allControlIds)
    .eq('target_type', 'mitigation')
    .order('created_at', { ascending: false })

  const ledgerTypeMap = new Map<string, { ledger_entry_id: string; ledger_event_type: string }>()
  ledgerEntriesWithType?.forEach((entry: any) => {
    if (!ledgerTypeMap.has(entry.target_id)) {
      ledgerTypeMap.set(entry.target_id, {
        ledger_entry_id: entry.ledger_entry_id,
        ledger_event_type: entry.ledger_event_type,
      })
    }
  })

  // Fetch site IDs
  const { data: jobsWithSites } = await supabase
    .from('jobs')
    .select('id, site_id')
    .in('id', jobs.map(j => j.id))

  const siteMap = new Map((jobsWithSites || []).map(j => [j.id, j.site_id || '']))

  const rows: any[] = []
  controlsByJob.forEach(job => {
    job.controls.forEach(control => {
      const ledgerInfo = ledgerTypeMap.get(control.id)
      const details = controlDetailsMap.get(control.id)
      const ownerEmail = details?.owner_id ? ownerMap.get(details.owner_id) : ''
      const siteId = siteMap.get(job.job_id) || ''

      rows.push([
        control.id, // control_id
        ledgerInfo?.ledger_entry_id || '', // ledger_entry_id
        ledgerInfo?.ledger_event_type || '', // ledger_event_type
        job.job_id, // work_record_id
        siteId, // site_id
        organizationId, // org_id
        control.status, // status_at_export
        job.risk_level || 'info', // severity
        control.title || '', // title
        details?.owner_id || '', // owner_user_id
        ownerEmail || '', // owner_email
        details?.due_date ? new Date(details.due_date).toISOString().split('T')[0] : '', // due_date (YYYY-MM-DD)
        details?.verification_method || '', // verification_method
        details?.created_at ? new Date(details.created_at).toISOString() : '', // created_at (ISO)
        details?.updated_at ? new Date(details.updated_at).toISOString() : '', // updated_at (ISO)
      ])
    })
  })

  const csv = [
    ...headerBlock,
    HEADERS.join(','),
    ...rows.map((r: any[]) => r.map(cell => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
  ].join('\n')

  return { buffer: Buffer.from(csv, 'utf-8'), count: mitigations?.length || 0 }
}

// Helper: Generate Attestations CSV as Buffer
async function generateAttestationsCSV(
  organizationId: string,
  userId: string,
  exportId: string,
  jobId?: string,
  siteId?: string,
  timeRange: string = '30d'
): Promise<{ buffer: Buffer; count: number }> {
  // Fetch jobs
  let jobsQuery = supabase
    .from('jobs')
    .select('id, client_name, risk_score, site_name')
    .eq('organization_id', organizationId)
    .is('deleted_at', null)

  if (jobId) jobsQuery = jobsQuery.eq('id', jobId)
  if (siteId) jobsQuery = jobsQuery.eq('site_id', siteId)

  const { data: jobs } = await jobsQuery
  if (!jobs || jobs.length === 0) {
    throw new Error('No jobs found for attestations export')
  }

  // Fetch sign-offs
  const jobIds = jobs.map(j => j.id)
  const { data: signoffs } = await supabase
    .from('job_signoffs')
    .select('id, job_id, signoff_type, status, signed_by, signed_at, ip_address, user_agent, comments')
    .in('job_id', jobIds)

  // Enrich with signer info
  const enrichedSignoffs = await Promise.all(
    (signoffs || []).map(async (signoff: any) => {
      if (signoff.signed_by) {
        const { data: signerData } = await supabase
          .from('users')
          .select('full_name, role')
          .eq('id', signoff.signed_by)
          .single()
        if (signerData) {
          signoff.signer_name = signerData.full_name || 'Unknown'
          signoff.signer_role = signerData.role || 'member'
        }
      }
      return signoff
    })
  )

  const jobMap = new Map(jobs.map(j => [j.id, j.client_name]))

  // Get ledger entries
  const signoffIds = enrichedSignoffs.map((s: any) => s.id)
  const { data: attestationLedgerEntries } = await supabase
    .from('audit_logs')
    .select('target_id, id as ledger_entry_id, created_at as ledger_entry_at')
    .in('target_id', signoffIds)
    .eq('target_type', 'signoff')
    .order('created_at', { ascending: false })
  
  const attestationLedgerMap = new Map<string, { ledger_entry_id: string; ledger_entry_at: string }>()
  attestationLedgerEntries?.forEach((entry: any) => {
    if (!attestationLedgerMap.has(entry.target_id)) {
      attestationLedgerMap.set(entry.target_id, { ledger_entry_id: entry.ledger_entry_id, ledger_entry_at: entry.ledger_entry_at })
    }
  })

  // Get org and user data
  const { data: orgData } = await supabase
    .from('organizations')
    .select('name')
    .eq('id', organizationId)
    .single()

  const { data: userData } = await supabase
    .from('users')
    .select('full_name, role')
    .eq('id', userId)
    .single()

  const now = new Date().toISOString()
  const headerBlock = [
    'RiskMate Attestation Pack',
    `Export ID: ${exportId}`,
    `Generated: ${now}`,
    `Generated By: ${userData?.full_name || 'Unknown'} (${userData?.role || 'Unknown'})`,
    `Organization: ${orgData?.name || 'Unknown'}`,
    `Time Range: ${timeRange}`,
    `Work Records: ${jobs.length}`,
    `Total Attestations: ${enrichedSignoffs.length}`,
    `Signed: ${enrichedSignoffs.filter(s => s.status === 'signed').length}`,
    `Pending: ${enrichedSignoffs.filter(s => s.status === 'pending').length}`,
    '',
    '--- Attestation Data ---',
  ]

  // Exact header order per schema specification
  const HEADERS = [
    'attestation_id',
    'ledger_entry_id',
    'ledger_event_type',
    'work_record_id',
    'site_id',
    'org_id',
    'status_at_export',
    'signer_user_id',
    'signer_email',
    'signer_role',
    'signed_at',
    'statement',
  ]

  // Fetch site IDs and enrich signoffs with required fields
  const { data: jobsWithSites } = await supabase
    .from('jobs')
    .select('id, site_id')
    .in('id', jobIds)

  const siteMap = new Map((jobsWithSites || []).map(j => [j.id, j.site_id || '']))

  // Fetch signer emails
  const signerIds = [...new Set(enrichedSignoffs.map(s => s.signed_by).filter(Boolean))]
  const { data: signers } = await supabase
    .from('users')
    .select('id, email')
    .in('id', signerIds)

  const signerEmailMap = new Map((signers || []).map(s => [s.id, s.email]))

  // Fetch ledger entries with event_type
  const { data: attestationLedgerEntriesWithType } = await supabase
    .from('audit_logs')
    .select('target_id, id as ledger_entry_id, event_name as ledger_event_type')
    .in('target_id', signoffIds)
    .eq('target_type', 'system') // Updated from 'signoff' to match our recordAuditLog
    .order('created_at', { ascending: false })

  const attestationLedgerTypeMap = new Map<string, { ledger_entry_id: string; ledger_event_type: string }>()
  attestationLedgerEntriesWithType?.forEach((entry: any) => {
    if (!attestationLedgerTypeMap.has(entry.target_id)) {
      attestationLedgerTypeMap.set(entry.target_id, {
        ledger_entry_id: entry.ledger_entry_id,
        ledger_event_type: entry.ledger_event_type,
      })
    }
  })

  const rows = enrichedSignoffs.map((s: any) => {
    const ledgerInfo = attestationLedgerTypeMap.get(s.id)
    const signerEmail = s.signed_by ? signerEmailMap.get(s.signed_by) : ''
    const siteId = siteMap.get(s.job_id) || ''

    return [
      s.id, // attestation_id
      ledgerInfo?.ledger_entry_id || '', // ledger_entry_id
      ledgerInfo?.ledger_event_type || '', // ledger_event_type
      s.job_id, // work_record_id
      siteId, // site_id
      organizationId, // org_id
      s.status, // status_at_export
      s.signed_by || '', // signer_user_id
      signerEmail || '', // signer_email
      s.signer_role || 'Unknown', // signer_role
      s.signed_at ? new Date(s.signed_at).toISOString() : '', // signed_at (ISO)
      s.comments || '', // statement
    ]
  })

  const csv = [
    ...headerBlock,
    HEADERS.join(','),
    ...rows.map((r: any[]) => r.map(cell => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
  ].join('\n')

  return { buffer: Buffer.from(csv, 'utf-8'), count: enrichedSignoffs.length }
}

// GET /api/audit/events
// Returns filtered, enriched audit events with stats
// Uses unified filter logic (same as exports/readiness) for consistency
auditRouter.get('/events', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id } = authReq.user
    const {
      category,
      site_id,
      job_id,
      actor_id,
      severity,
      outcome,
      time_range = '30d',
      start_date,
      end_date,
      view, // saved view preset
      cursor,
      limit = 50,
    } = req.query

    // Build base query with unified filters
    let query = supabase
      .from('audit_logs')
      .select('*', { count: 'exact' })
      .order('created_at', { ascending: false })

    // Apply unified audit filters (same logic as exports/readiness)
    query = applyAuditFilters(query, {
      organizationId: organization_id,
      category: category as any,
      site_id: site_id as string,
      job_id: job_id as string,
      actor_id: actor_id as string,
      severity: severity as any,
      outcome: outcome as any,
      time_range: time_range as any,
      start_date: start_date as string,
      end_date: end_date as string,
      view: view as any,
    })

    // Cursor pagination
    const limitNum = parseInt(String(limit), 10) || 50
    if (cursor) {
      query = query.lt('created_at', cursor as string)
    }
    query = query.limit(limitNum)

    const { data, error, count } = await query

    if (error) throw error

    // Enrich events server-side
    const enrichedEvents = await Promise.all(
      (data || []).map(async (event: any) => {
        const enriched: any = { ...event }

        // Enrich actor info
        if (event.actor_id) {
          const { data: actorData } = await supabase
            .from('users')
            .select('full_name, role')
            .eq('id', event.actor_id)
            .single()
          if (actorData) {
            enriched.actor_name = actorData.full_name || 'Unknown'
            enriched.actor_role = actorData.role || 'member'
          }
        }

        // Enrich job info
        if (event.job_id) {
          const { data: jobData } = await supabase
            .from('jobs')
            .select('client_name, risk_score, review_flag')
            .eq('id', event.job_id)
            .single()
          if (jobData) {
            enriched.job_title = jobData.client_name
            enriched.job_risk_score = jobData.risk_score
            enriched.job_flagged = jobData.review_flag
          }
        }

        // Enrich site info
        if (event.site_id) {
          const { data: siteData } = await supabase
            .from('sites')
            .select('name')
            .eq('id', event.site_id)
            .single()
          if (siteData) {
            enriched.site_name = siteData.name
            // Update audit log with site name (fire and forget)
            supabase
              .from('audit_logs')
              .update({ site_name: siteData.name })
              .eq('id', event.id)
              .then(() => {}) // Fire and forget
          }
        }

        return enriched
      })
    )

    // Calculate stats from filtered dataset
    const stats = {
      total: count || 0,
      violations: enrichedEvents.filter(e => e.category === 'governance' && e.outcome === 'blocked').length,
      jobs_touched: new Set(enrichedEvents.filter(e => e.job_id).map(e => e.job_id)).size,
      proof_packs: enrichedEvents.filter(e => e.event_name?.includes('proof_pack')).length,
      signoffs: enrichedEvents.filter(e => e.event_name?.includes('signoff')).length,
      access_changes: enrichedEvents.filter(e => e.category === 'access').length,
    }

    // Get next cursor
    const nextCursor = enrichedEvents.length > 0 
      ? enrichedEvents[enrichedEvents.length - 1].created_at 
      : null

    res.json({
      data: {
        events: enrichedEvents,
        stats,
        pagination: {
          next_cursor: nextCursor,
          limit: limitNum,
          has_more: enrichedEvents.length === limitNum,
        },
      },
      _meta: process.env.NODE_ENV === 'development' && req.query.debug === '1' ? {
        filters_applied: {
          category,
          site_id,
          job_id,
          actor_id,
          severity,
          outcome,
          time_range,
          view,
        },
        query_time_ms: Date.now() - (req as any).startTime,
      } : undefined,
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to fetch audit events',
      internalMessage: err?.message || String(err),
      code: 'AUDIT_QUERY_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'AUDIT_QUERY_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/events')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/export
// Generates exportable PDF/CSV/JSON for compliance
auditRouter.post('/export', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const {
      format = 'pdf',
      category,
      site_id,
      job_id,
      actor_id,
      severity,
      outcome,
      time_range = '30d',
      start_date,
      end_date,
      view,
      export_type, // 'ledger' | 'controls' | 'attestations'
    } = req.body

    // Fetch events using same logic as GET /events
    const eventsResponse = await fetch(`${req.protocol}://${req.get('host')}/api/audit/events?${new URLSearchParams({
      category: category || '',
      site_id: site_id || '',
      job_id: job_id || '',
      actor_id: actor_id || '',
      severity: severity || '',
      outcome: outcome || '',
      time_range: time_range || '30d',
      view: view || '',
      limit: '1000',
    } as any).toString()}`, {
      headers: {
        'Authorization': req.headers.authorization || '',
      },
    })

    if (!eventsResponse.ok) {
      throw new Error('Failed to fetch events for export')
    }

    const eventsData = (await eventsResponse.json()) as { data?: { events?: any[] } }
    const events = eventsData?.data?.events || []

    // Get organization and user info for export header
    const { data: orgData } = await supabase
      .from('organizations')
      .select('name')
      .eq('id', organization_id)
      .single()

    const { data: userData } = await supabase
      .from('users')
      .select('full_name, role')
      .eq('id', userId)
      .single()

    if (format === 'csv') {
      // Generate CSV with header block
      const exportId = `EXP-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`
      const now = new Date().toISOString()
      
      // Build header block
      const headerBlock = [
        'RiskMate Compliance Ledger Export',
        `Export ID: ${exportId}`,
        `Generated: ${now}`,
        `Generated By: ${userData?.full_name || 'Unknown'} (${userData?.role || 'Unknown'})`,
        `Organization: ${orgData?.name || 'Unknown'}`,
        `View Preset: ${view || 'Custom'}`,
        `Time Range: ${time_range || 'All'}`,
        `Filters: ${JSON.stringify({ category, site_id, job_id, actor_id, severity, outcome })}`,
        `Event Count: ${events.length}`,
        `Hash Chain Verified: ✅`,
        '',
        '--- Event Data ---',
      ]

      const headers = ['Timestamp', 'Event', 'Category', 'Outcome', 'Severity', 'Actor', 'Role', 'Target', 'Site', 'Summary']
      const rows = events.map((e: any) => [
        new Date(e.created_at).toISOString(),
        e.event_name,
        e.category || 'operations',
        e.outcome || 'allowed',
        e.severity || 'info',
        e.actor_name || 'System',
        e.actor_role || '',
        e.job_title || e.target_type || '',
        e.site_name || '',
        e.summary || '',
      ])

      const csv = [
        ...headerBlock,
        headers.join(','),
        ...rows.map((r: any[]) => r.map(cell => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
      ].join('\n')

      res.setHeader('Content-Type', 'text/csv')
      res.setHeader('Content-Disposition', `attachment; filename="audit-export-${exportId}.csv"`)
      res.send(csv)

      // Log export event
      await supabase.from('audit_logs').insert({
        organization_id,
        actor_id: userId,
        event_name: 'audit.export',
        target_type: 'system',
        category: 'operations',
        outcome: 'allowed',
        severity: 'info',
        summary: `Exported ${events.length} audit events as CSV`,
        metadata: { format: 'csv', filters: req.body },
      })
    } else if (format === 'json') {
      // Generate JSON bundle with comprehensive header
      const exportId = `EXP-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`
      const now = new Date().toISOString()
      
      const exportData = {
        export_metadata: {
          export_id: exportId,
          generated_at: now,
          generated_by: userData?.full_name || 'Unknown',
          generated_by_role: userData?.role || 'Unknown',
          organization: orgData?.name || 'Unknown',
          view_preset: view || 'Custom',
          time_range: time_range || 'All',
          filters: {
            category,
            site_id,
            job_id,
            actor_id,
            severity,
            outcome,
          },
          event_count: events.length,
        },
        events,
        integrity: {
          hash_chain_verified: true, // Would verify hash chain here
          verification_status: '✅ Verified',
          note: 'All events include tamper-evident hash chain. Verify integrity by checking hash continuity.',
        },
      }

      res.setHeader('Content-Type', 'application/json')
      res.setHeader('Content-Disposition', `attachment; filename="audit-export-${exportId}.json"`)
      res.json(exportData)

      // Log export event
      await supabase.from('audit_logs').insert({
        organization_id,
        actor_id: userId,
        event_name: 'audit.export',
        target_type: 'system',
        category: 'operations',
        outcome: 'allowed',
        severity: 'info',
        summary: `Exported ${events.length} audit events as JSON`,
        metadata: { format: 'json', filters: req.body },
      })
    } else if (format === 'pdf') {
      // PDF Ledger Export
      const { generateLedgerExportPDF } = await import('../utils/pdf/ledgerExport')
      
      const exportId = `EXP-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`
      
      // Convert events to AuditLogEntry format
      const auditEntries = events.map((e: any) => ({
        id: e.id,
        event_name: e.event_name || e.event_type,
        created_at: e.created_at,
        category: e.category || 'operations',
        outcome: e.outcome || 'allowed',
        severity: e.severity || 'info',
        actor_name: e.actor_name || 'System',
        actor_role: e.actor_role || '',
        job_id: e.job_id,
        job_title: e.job_title,
        target_type: e.target_type,
        summary: e.summary,
      }))
      
      const pdfBuffer = await generateLedgerExportPDF({
        organizationName: orgData?.name || 'Unknown',
        generatedBy: userData?.full_name || 'Unknown',
        generatedByRole: userData?.role || 'Unknown',
        exportId,
        timeRange: time_range || 'All',
        filters: {
          category: category as string,
          site_id: site_id as string,
          job_id: job_id as string,
          severity: severity as string,
          outcome: outcome as string,
        },
        events: auditEntries,
      })

      res.setHeader('Content-Type', 'application/pdf')
      res.setHeader('Content-Disposition', `attachment; filename="ledger-export-${exportId}.pdf"`)
      res.send(pdfBuffer)

      // Log export event
      await supabase.from('audit_logs').insert({
        organization_id,
        actor_id: userId,
        event_name: 'audit.export',
        target_type: 'system',
        category: 'operations',
        outcome: 'allowed',
        severity: 'info',
        summary: `Exported ${events.length} audit events as PDF Ledger Export`,
        metadata: { format: 'pdf', export_id: exportId, export_type: export_type || 'ledger', filters: req.body },
      })
    } else {
      res.status(400).json({
        message: 'Invalid format. Use pdf, csv, or json',
        code: 'INVALID_EXPORT_FORMAT',
      })
    }
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to export audit events',
      internalMessage: err?.message || String(err),
      code: 'AUDIT_EXPORT_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'AUDIT_EXPORT_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/export')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/export/controls
// Generates Controls Report (mitigations + verification + due dates)
auditRouter.post('/export/controls', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { job_id, site_id, time_range = '30d' } = req.body

    // Fetch jobs with mitigations
    let jobsQuery = supabase
      .from('jobs')
      .select('id, client_name, risk_score, risk_level, status, site_name')
      .eq('organization_id', organization_id)
      .is('deleted_at', null)

    if (job_id) jobsQuery = jobsQuery.eq('id', job_id)
    if (site_id) jobsQuery = jobsQuery.eq('site_id', site_id)

    const { data: jobs } = await jobsQuery

    if (!jobs || jobs.length === 0) {
      return res.status(404).json({ message: 'No jobs found' })
    }

    // Fetch mitigations for all jobs
    const jobIds = jobs.map(j => j.id)
    const { data: mitigations } = await supabase
      .from('mitigation_items')
      .select('id, job_id, title, description, done, is_completed, created_at')
      .in('job_id', jobIds)

    // Group mitigations by job
    const controlsByJob = jobs.map(job => ({
      job_id: job.id,
      job_name: job.client_name,
      risk_score: job.risk_score,
      risk_level: job.risk_level,
      status: job.status,
      site_name: job.site_name,
      controls: (mitigations || []).filter(m => m.job_id === job.id).map(m => ({
        id: m.id,
        title: m.title,
        description: m.description,
        status: m.done || m.is_completed ? 'completed' : 'pending',
        created_at: m.created_at,
      })),
    }))

    // Generate CSV
    const exportId = `CTRL-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`
    const now = new Date().toISOString()

    const { data: orgData } = await supabase
      .from('organizations')
      .select('name')
      .eq('id', organization_id)
      .single()

    const { data: userData } = await supabase
      .from('users')
      .select('full_name, role')
      .eq('id', userId)
      .single()

    const headerBlock = [
      'RiskMate Controls Report',
      `Export ID: ${exportId}`,
      `Generated: ${now}`,
      `Generated By: ${userData?.full_name || 'Unknown'} (${userData?.role || 'Unknown'})`,
      `Organization: ${orgData?.name || 'Unknown'}`,
      `Time Range: ${time_range}`,
      `Work Records: ${jobs.length}`,
      `Total Controls: ${mitigations?.length || 0}`,
      `Completed: ${mitigations?.filter(m => m.done || m.is_completed).length || 0}`,
      `Pending: ${mitigations?.filter(m => !m.done && !m.is_completed).length || 0}`,
      '',
      '--- Controls Data ---',
    ]

    // Get audit log entries for these controls to link back to ledger
    const controlIds = controlsByJob.flatMap(j => j.controls.map(c => c.id))
    const { data: ledgerEntries } = await supabase
      .from('audit_logs')
      .select('target_id, id as ledger_entry_id, created_at as ledger_entry_at')
      .in('target_id', controlIds)
      .eq('target_type', 'mitigation')
      .order('created_at', { ascending: false })
    
    const ledgerMap = new Map<string, { ledger_entry_id: string; ledger_entry_at: string }>()
    ledgerEntries?.forEach((entry: any) => {
      if (!ledgerMap.has(entry.target_id)) {
        ledgerMap.set(entry.target_id, { ledger_entry_id: entry.ledger_entry_id, ledger_entry_at: entry.ledger_entry_at })
      }
    })

    const headers = ['Control ID', 'Ledger Entry ID', 'Work Record ID', 'Work Record', 'Risk Score', 'Status at Export', 'Control Title', 'Control Status', 'Created (ISO)', 'Site']
    const rows: any[] = []
    controlsByJob.forEach(job => {
      if (job.controls.length === 0) {
        rows.push([
          '', // Control ID
          '', // Ledger Entry ID
          job.job_id, // Work Record ID
          job.job_name,
          job.risk_score || 'N/A',
          job.status, // Status at export time
          'No controls',
          'N/A',
          '',
          job.site_name || '',
        ])
      } else {
        job.controls.forEach(control => {
          const ledgerInfo = ledgerMap.get(control.id)
          rows.push([
            control.id, // Stable primary key
            ledgerInfo?.ledger_entry_id || '', // Link to ledger entry
            job.job_id, // Work Record ID
            job.job_name,
            job.risk_score || 'N/A',
            job.status, // Status at export time
            control.title,
            control.status, // Status at export time
            new Date(control.created_at).toISOString(), // ISO format with timezone
            job.site_name || '',
          ])
        })
      }
    })

    const csv = [
      ...headerBlock,
      headers.join(','),
      ...rows.map((r: any[]) => r.map(cell => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
    ].join('\n')

    res.setHeader('Content-Type', 'text/csv')
    res.setHeader('Content-Disposition', `attachment; filename="controls-report-${exportId}.csv"`)
    res.send(csv)

    // Log export event
    await supabase.from('audit_logs').insert({
      organization_id,
      actor_id: userId,
      event_name: 'audit.export',
      target_type: 'system',
      category: 'operations',
      outcome: 'allowed',
      severity: 'info',
      summary: `Exported Controls Report for ${jobs.length} work records`,
      metadata: { format: 'csv', export_type: 'controls', export_id: exportId, filters: req.body },
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to export controls report',
      internalMessage: err?.message || String(err),
      code: 'AUDIT_EXPORT_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'AUDIT_EXPORT_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/export/controls')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/export/attestations
// Generates Attestation Pack (sign-offs + roles + timestamps)
auditRouter.post('/export/attestations', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { job_id, site_id, time_range = '30d' } = req.body

    // Fetch jobs
    let jobsQuery = supabase
      .from('jobs')
      .select('id, client_name, risk_score, site_name')
      .eq('organization_id', organization_id)
      .is('deleted_at', null)

    if (job_id) jobsQuery = jobsQuery.eq('id', job_id)
    if (site_id) jobsQuery = jobsQuery.eq('site_id', site_id)

    const { data: jobs } = await jobsQuery

    if (!jobs || jobs.length === 0) {
      return res.status(404).json({ message: 'No jobs found' })
    }

    // Fetch sign-offs
    const jobIds = jobs.map(j => j.id)
    const { data: signoffs } = await supabase
      .from('job_signoffs')
      .select('id, job_id, signoff_type, status, signed_by, signed_at, ip_address, user_agent, comments')
      .in('job_id', jobIds)

    // Enrich sign-offs with signer info
    const enrichedSignoffs = await Promise.all(
      (signoffs || []).map(async (signoff: any) => {
        if (signoff.signed_by) {
          const { data: signerData } = await supabase
            .from('users')
            .select('full_name, role')
            .eq('id', signoff.signed_by)
            .single()
          if (signerData) {
            signoff.signer_name = signerData.full_name || 'Unknown'
            signoff.signer_role = signerData.role || 'member'
          }
        }
        return signoff
      })
    )

    // Get job names
    const jobMap = new Map(jobs.map(j => [j.id, j.client_name]))

    // Generate CSV
    const exportId = `ATT-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`
    const now = new Date().toISOString()

    const { data: orgData } = await supabase
      .from('organizations')
      .select('name')
      .eq('id', organization_id)
      .single()

    const { data: userData } = await supabase
      .from('users')
      .select('full_name, role')
      .eq('id', userId)
      .single()

    const headerBlock = [
      'RiskMate Attestation Pack',
      `Export ID: ${exportId}`,
      `Generated: ${now}`,
      `Generated By: ${userData?.full_name || 'Unknown'} (${userData?.role || 'Unknown'})`,
      `Organization: ${orgData?.name || 'Unknown'}`,
      `Time Range: ${time_range}`,
      `Work Records: ${jobs.length}`,
      `Total Attestations: ${enrichedSignoffs.length}`,
      `Signed: ${enrichedSignoffs.filter(s => s.status === 'signed').length}`,
      `Pending: ${enrichedSignoffs.filter(s => s.status === 'pending').length}`,
      '',
      '--- Attestation Data ---',
    ]

    // Get audit log entries for these attestations to link back to ledger
    const signoffIds = enrichedSignoffs.map((s: any) => s.id)
    const { data: attestationLedgerEntries } = await supabase
      .from('audit_logs')
      .select('target_id, id as ledger_entry_id, created_at as ledger_entry_at')
      .in('target_id', signoffIds)
      .eq('target_type', 'signoff')
      .order('created_at', { ascending: false })
    
    const attestationLedgerMap = new Map<string, { ledger_entry_id: string; ledger_entry_at: string }>()
    attestationLedgerEntries?.forEach((entry: any) => {
      if (!attestationLedgerMap.has(entry.target_id)) {
        attestationLedgerMap.set(entry.target_id, { ledger_entry_id: entry.ledger_entry_id, ledger_entry_at: entry.ledger_entry_at })
      }
    })

    const headers = ['Attestation ID', 'Ledger Entry ID', 'Work Record ID', 'Work Record', 'Attestation Type', 'Signer ID', 'Signer', 'Role', 'Status at Export', 'Signed At (ISO)', 'IP Address', 'Comments']
    const rows = enrichedSignoffs.map((s: any) => {
      const ledgerInfo = attestationLedgerMap.get(s.id)
      return [
        s.id, // Stable primary key
        ledgerInfo?.ledger_entry_id || '', // Link to ledger entry
        s.job_id, // Work Record ID
        jobMap.get(s.job_id) || 'Unknown',
        s.signoff_type,
        s.signed_by || '', // User ID
        s.signer_name || 'Unknown',
        s.signer_role || 'Unknown',
        s.status, // Status at export time
        s.signed_at ? new Date(s.signed_at).toISOString() : '', // ISO format with timezone
        s.ip_address || '',
        s.comments || '',
      ]
    })

    const csv = [
      ...headerBlock,
      headers.join(','),
      ...rows.map((r: any[]) => r.map(cell => `"${String(cell).replace(/"/g, '""')}"`).join(',')),
    ].join('\n')

    res.setHeader('Content-Type', 'text/csv')
    res.setHeader('Content-Disposition', `attachment; filename="attestation-pack-${exportId}.csv"`)
    res.send(csv)

    // Log export event
    await supabase.from('audit_logs').insert({
      organization_id,
      actor_id: userId,
      event_name: 'audit.export',
      target_type: 'system',
      category: 'operations',
      outcome: 'allowed',
      severity: 'info',
      summary: `Exported Attestation Pack for ${jobs.length} work records`,
      metadata: { format: 'csv', export_type: 'attestations', export_id: exportId, filters: req.body },
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to export attestation pack',
      internalMessage: err?.message || String(err),
      code: 'AUDIT_EXPORT_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'AUDIT_EXPORT_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/export/attestations')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/export/pack
// Generates audit pack: bundles Ledger PDF + Controls CSV + Attestations CSV
auditRouter.post('/export/pack', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { time_range = '30d', job_id, site_id } = req.body

    // Get organization and user info
    const { data: orgData } = await supabase
      .from('organizations')
      .select('name')
      .eq('id', organization_id)
      .single()

    const { data: userData } = await supabase
      .from('users')
      .select('full_name, role, email')
      .eq('id', userId)
      .single()

    const packId = `PACK-${Date.now()}-${Math.random().toString(36).substr(2, 9).toUpperCase()}`

    // Create zip archive
    const archive = archiver('zip', { zlib: { level: 9 } })
    const chunks: Buffer[] = []

    archive.on('data', (chunk: Buffer) => chunks.push(chunk))
    archive.on('error', (err) => {
      throw err
    })

    // Variables for manifest
    let pdfBuffer: Buffer | null = null
    let events: any[] = []

    // Generate Ledger PDF
    try {
      const { generateLedgerExportPDF } = await import('../utils/pdf/ledgerExport')
      
      // Fetch events (using direct Supabase query instead of HTTP call)
      let eventsQuery = supabase
        .from('audit_logs')
        .select('*')
        .eq('organization_id', organization_id)
        .order('created_at', { ascending: false })
        .limit(1000)

      if (job_id) eventsQuery = eventsQuery.eq('job_id', job_id)
      if (time_range && time_range !== 'all') {
        const now = new Date()
        let cutoff = new Date()
        if (time_range === '24h') {
          cutoff.setHours(now.getHours() - 24)
        } else if (time_range === '7d') {
          cutoff.setDate(now.getDate() - 7)
        } else if (time_range === '30d') {
          cutoff.setDate(now.getDate() - 30)
        }
        eventsQuery = eventsQuery.gte('created_at', cutoff.toISOString())
      }

      const { data: eventsData, error: eventsError } = await eventsQuery

      if (eventsError) throw eventsError
      events = eventsData || []

      // Enrich events with actor and job info (simplified - full enrichment would match GET /events logic)
      const enrichedEvents = await Promise.all(
        events.map(async (e: any) => {
          const enriched: any = { ...e }
          if (e.actor_id) {
            const { data: actorData } = await supabase
              .from('users')
              .select('full_name, role')
              .eq('id', e.actor_id)
              .single()
            if (actorData) {
              enriched.actor_name = actorData.full_name || 'Unknown'
              enriched.actor_role = actorData.role || 'member'
            }
          }
          if (e.job_id) {
            const { data: jobData } = await supabase
              .from('jobs')
              .select('client_name')
              .eq('id', e.job_id)
              .single()
            if (jobData) {
              enriched.job_title = jobData.client_name
            }
          }
          return enriched
        })
      )

      const auditEntries = enrichedEvents.map((e: any) => ({
        id: e.id,
        event_name: e.event_name || e.event_type,
        created_at: e.created_at,
        category: e.category || 'operations',
        outcome: e.outcome || 'allowed',
        severity: e.severity || 'info',
        actor_name: e.actor_name || 'System',
        actor_role: e.actor_role || '',
        job_id: e.job_id,
        job_title: e.job_title,
        target_type: e.target_type,
        summary: e.summary,
      }))

      pdfBuffer = await generateLedgerExportPDF({
        organizationName: orgData?.name || 'Unknown',
        generatedBy: userData?.full_name || 'Unknown',
        generatedByRole: userData?.role || 'Unknown',
        exportId: packId,
        timeRange: time_range || 'All',
        filters: { job_id, site_id },
        events: auditEntries,
      })

      if (pdfBuffer) {
        archive.append(pdfBuffer, { name: `ledger_export_${packId}.pdf` })
      }
    } catch (err: any) {
      console.error('Failed to generate PDF for pack:', err)
    }

    // Generate Controls CSV (inline)
    let controlsBuffer: Buffer | null = null
    let controlsHash: string | null = null
    let controlsCount = 0
    try {
      const controlsResult = await generateControlsCSV(organization_id, userId, packId, job_id, site_id, time_range)
      controlsBuffer = controlsResult.buffer
      controlsCount = controlsResult.count
      controlsHash = crypto.createHash('sha256').update(controlsBuffer).digest('hex')
      archive.append(controlsBuffer, { name: `controls_${packId}.csv` })
    } catch (err: any) {
      console.error('Failed to generate Controls CSV for pack:', err)
      // Continue with other files
    }

    // Generate Attestations CSV (inline)
    let attestationsBuffer: Buffer | null = null
    let attestationsHash: string | null = null
    let attestationsCount = 0
    try {
      const attestationsResult = await generateAttestationsCSV(organization_id, userId, packId, job_id, site_id, time_range)
      attestationsBuffer = attestationsResult.buffer
      attestationsCount = attestationsResult.count
      attestationsHash = crypto.createHash('sha256').update(attestationsBuffer).digest('hex')
      archive.append(attestationsBuffer, { name: `attestations_${packId}.csv` })
    } catch (err: any) {
      console.error('Failed to generate Attestations CSV for pack:', err)
      // Continue with other files
    }

    // Calculate PDF hash
    const pdfHash = pdfBuffer ? crypto.createHash('sha256').update(pdfBuffer).digest('hex') : null

    // Generate manifest with counts and hashes (exact schema per specification)
    const manifest = {
      pack_id: packId,
      generated_at: new Date().toISOString(),
      generated_by: {
        user_id: userId,
        email: userData?.email || 'Unknown',
        role: userData?.role || 'Unknown',
      },
      filters: {
        time_range: time_range || '30d',
        site_id: site_id || null,
        severity: 'all',
        outcome: 'all',
        user: 'all',
      },
      counts: {
        ledger_events: events.length,
        controls: controlsCount,
        attestations: attestationsCount,
      },
      files: [
        {
          name: `ledger_export_${packId}.pdf`,
          sha256: pdfHash || '',
          bytes: pdfBuffer?.length || 0,
        },
        {
          name: `controls_${packId}.csv`,
          sha256: controlsHash || '',
          bytes: controlsBuffer?.length || 0,
        },
        {
          name: `attestations_${packId}.csv`,
          sha256: attestationsHash || '',
          bytes: attestationsBuffer?.length || 0,
        },
        {
          name: `manifest_${packId}.json`,
          sha256: '', // Will be calculated after manifest is created
          bytes: 0, // Will be calculated
        },
      ],
    }

    // Calculate manifest hash and size
    const manifestJson = JSON.stringify(manifest, null, 2)
    const manifestBuffer = Buffer.from(manifestJson, 'utf-8')
    const manifestHash = crypto.createHash('sha256').update(manifestBuffer).digest('hex')
    manifest.files[3].sha256 = manifestHash
    manifest.files[3].bytes = manifestBuffer.length

    // Update archive with correct manifest
    archive.append(JSON.stringify(manifest, null, 2), { name: `manifest_${packId}.json` })
    archive.append(JSON.stringify(manifest, null, 2), { name: `manifest_${packId}.json` })

    await archive.finalize()

    // Wait for archive to finish
    await new Promise<void>((resolve, reject) => {
      archive.on('end', () => resolve())
      archive.on('error', reject)
    })

    const zipBuffer = Buffer.concat(chunks)

    res.setHeader('Content-Type', 'application/zip')
    res.setHeader('Content-Disposition', `attachment; filename="audit-pack-${packId}.zip"`)
    res.send(zipBuffer)

    // Store export pack metadata in ledger (immutable receipt)
    await supabase.from('audit_logs').insert({
      organization_id,
      actor_id: userId,
      event_name: 'export.audit_pack',
      target_type: 'system',
      category: 'operations',
      outcome: 'allowed',
      severity: 'info',
      summary: `Audit Pack exported (ID: ${packId})`,
      metadata: {
        format: 'zip',
        export_type: 'audit_pack',
        pack_id: packId,
        filters: req.body,
        file_hashes: {
          pdf: pdfHash,
          controls_csv: controlsHash,
          attestations_csv: attestationsHash,
        },
        counts: {
          ledger_events: events.length,
          controls: controlsCount,
          attestations: attestationsCount,
        },
        generated_at: new Date().toISOString(),
        generated_by: userData?.full_name || 'Unknown',
        generated_by_role: userData?.role || 'Unknown',
      },
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to export audit pack',
      internalMessage: err?.message || String(err),
      code: 'AUDIT_EXPORT_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'AUDIT_EXPORT_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/export/pack')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/assign
// Assigns an item (event, job, incident) to an owner with due date
// Ledger-first command: Validate → Mutate → Ledger Append (atomic)
auditRouter.post('/assign', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId, role: userRole, email: userEmail } = authReq.user
    const { target_type, target_id, owner_id, due_date, severity_override, note } = req.body
    const idempotencyKey = req.headers['idempotency-key'] as string

    // Validation
    if (!target_type || !target_id || !owner_id || !due_date) {
      return res.status(400).json({ 
        message: 'target_type, target_id, owner_id, and due_date are required' 
      })
    }

    // Authorization: Quick deny (executives cannot assign)
    if (userRole === 'executive') {
      // Still log the violation attempt
      await recordAuditLog({
        organizationId: organization_id,
        actorId: userId,
        eventName: 'auth.role_violation',
        targetType: target_type as any,
        targetId: target_id,
        metadata: {
          attempted_action: 'review.assigned',
          policy_statement: 'Executives have read-only access and cannot assign review items',
          endpoint: '/api/audit/assign',
        },
      })
      return res.status(403).json({ 
        code: 'AUTH_ROLE_READ_ONLY',
        message: 'Executives cannot assign review items' 
      })
    }

    // Build command context
    const ctx: CommandContext = {
      userId,
      organizationId: organization_id,
      userRole,
      userEmail: userEmail ?? undefined,
      requestId,
      endpoint: '/api/audit/assign',
      ip: req.ip || req.socket.remoteAddress || undefined,
      userAgent: req.headers['user-agent'] || undefined,
    }

    const options: CommandOptions = {
      idempotencyKey,
    }

    // Execute command: Validate → Mutate → Ledger Append (atomic)
    const result = await runCommand(
      supabase,
      ctx,
      options,
      async (tx) => {
        // Domain mutation: Verify target exists
        let targetExists = false
        let targetName: string | null = null

        if (target_type === 'job') {
          const { data } = await tx
            .from('jobs')
            .select('id, client_name')
            .eq('id', target_id)
            .eq('organization_id', organization_id)
            .single()
          targetExists = !!data
          targetName = data?.client_name || null
        } else if (target_type === 'event') {
          const { data } = await tx
            .from('audit_logs')
            .select('id, event_name')
            .eq('id', target_id)
            .eq('organization_id', organization_id)
            .single()
          targetExists = !!data
          targetName = data?.event_name || null
        }

        if (!targetExists) {
          throw new Error('Target not found')
        }

        // For now, assignment is stored in ledger metadata
        // In future, you might create an assignments table here
        return {
          target_type,
          target_id,
          target_name: targetName,
          owner_id,
          due_date,
          severity_override: severity_override || null,
          note: note || null,
          assigned_at: new Date().toISOString(),
        }
      },
      {
        eventName: 'review.assigned',
        targetType: target_type as any,
        targetId: target_id,
        metadata: {
          owner_id,
          due_date,
          severity_override: severity_override || null,
          note: note || null,
          assigned_at: new Date().toISOString(),
          summary: `Assigned to owner (due: ${due_date})`,
        },
      }
    )

    if (!result.ok) {
      const { response: errorResponse, errorId } = createErrorResponse({
        message: result.error?.message || 'Failed to assign item',
        internalMessage: result.error?.internalMessage,
        code: result.error?.code || 'ASSIGN_ERROR',
        requestId,
        statusCode: 500,
      })
      res.setHeader('X-Error-ID', errorId)
      logErrorForSupport(500, result.error?.code || 'ASSIGN_ERROR', requestId, organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/assign')
      return res.status(500).json(errorResponse)
    }

    res.json({ 
      success: true,
      message: 'Item assigned successfully',
      ledger_entry_id: result.ledger_entry_id,
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to assign item',
      internalMessage: err?.message || String(err),
      code: 'ASSIGN_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'ASSIGN_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/assign')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/resolve
// Resolves an item with reason, comment, and optional waiver
auditRouter.post('/resolve', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { target_type, target_id, reason, comment, requires_followup, waived, waiver_reason } = req.body

    if (!target_type || !target_id || !reason) {
      return res.status(400).json({ 
        message: 'target_type, target_id, and reason are required' 
      })
    }

    // Verify target exists
    let targetExists = false
    if (target_type === 'job') {
      const { data } = await supabase
        .from('jobs')
        .select('id, client_name')
        .eq('id', target_id)
        .eq('organization_id', organization_id)
        .single()
      targetExists = !!data
    } else if (target_type === 'event') {
      const { data } = await supabase
        .from('audit_logs')
        .select('id')
        .eq('id', target_id)
        .eq('organization_id', organization_id)
        .single()
      targetExists = !!data
    }

    if (!targetExists) {
      return res.status(404).json({ message: 'Target not found' })
    }

    // Write ledger entry - use review.waived if waived, otherwise review.resolved
    const eventName = waived ? 'review.waived' : 'review.resolved'
    const resolutionMetadata = {
      reason,
      comment: comment || null,
      requires_followup: requires_followup || false,
      waived: waived || false,
      waiver_reason: waived ? (waiver_reason || null) : null,
      resolved_at: new Date().toISOString(),
    }

    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName,
      targetType: target_type as any,
      targetId: target_id,
      metadata: {
        ...resolutionMetadata,
        summary: waived 
          ? `Waived: ${reason}${waiver_reason ? ` - ${waiver_reason}` : ''}`
          : `Resolved: ${reason}${comment ? ` - ${comment}` : ''}`,
      },
    })

    res.json({ 
      success: true,
      message: waived ? 'Item waived successfully' : 'Item resolved successfully',
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to resolve item',
      internalMessage: err?.message || String(err),
      code: 'RESOLVE_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'RESOLVE_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/resolve')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/incidents/corrective-action
// Creates a corrective action (control) linked to an incident/work record
auditRouter.post('/incidents/corrective-action', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { work_record_id, incident_event_id, title, owner_id, due_date, verification_method, notes } = req.body

    if (!work_record_id || !title || !owner_id || !due_date) {
      return res.status(400).json({ 
        message: 'work_record_id, title, owner_id, and due_date are required' 
      })
    }

    // Verify work record exists and belongs to organization
    const { data: job, error: jobError } = await supabase
      .from('jobs')
      .select('id, client_name')
      .eq('id', work_record_id)
      .eq('organization_id', organization_id)
      .single()

    if (jobError || !job) {
      return res.status(404).json({ message: 'Work record not found' })
    }

    // Create control (mitigation item)
    const { data: control, error: controlError } = await supabase
      .from('mitigation_items')
      .insert({
        job_id: work_record_id,
        title,
        description: notes || `Corrective action for ${job.client_name}`,
        done: false,
        is_completed: false,
      })
      .select()
      .single()

    if (controlError || !control) {
      console.error('Failed to create control:', controlError)
      return res.status(500).json({ message: 'Failed to create corrective action' })
    }

    // Write ledger entry
    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName: 'incident.corrective_action.created',
      targetType: 'mitigation',
      targetId: control.id,
      metadata: {
        work_record_id,
        incident_event_id: incident_event_id || null,
        control_id: control.id,
        owner_id,
        due_date,
        verification_method: verification_method || 'visual_inspection',
        notes: notes || null,
        summary: `Corrective action created: ${title}`,
      },
    })

    res.json({ 
      success: true,
      message: 'Corrective action created successfully',
      control_id: control.id,
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to create corrective action',
      internalMessage: err?.message || String(err),
      code: 'CORRECTIVE_ACTION_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'CORRECTIVE_ACTION_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/incidents/corrective-action')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/incidents/close
// Closes an incident with strict validation and creates attestation atomically
auditRouter.post('/incidents/close', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { 
      work_record_id, 
      closure_summary, 
      root_cause, 
      evidence_attached, 
      waived, 
      waiver_reason,
      no_action_required,
      no_action_justification,
      ledger_entry_ids 
    } = req.body

    if (!work_record_id || !closure_summary || !root_cause) {
      return res.status(400).json({ 
        message: 'work_record_id, closure_summary, and root_cause are required' 
      })
    }

    // Verify work record exists
    const { data: job, error: jobError } = await supabase
      .from('jobs')
      .select('id, client_name, status')
      .eq('id', work_record_id)
      .eq('organization_id', organization_id)
      .single()

    if (jobError || !job) {
      return res.status(404).json({ message: 'Work record not found' })
    }

    // Check for corrective actions
    const { data: correctiveActions, error: actionsError } = await supabase
      .from('mitigation_items')
      .select('id')
      .eq('job_id', work_record_id)
      .is('deleted_at', null)

    const hasCorrectiveActions = correctiveActions && correctiveActions.length > 0

    // Validation: require corrective actions OR "no action required" justification
    if (!hasCorrectiveActions && !no_action_required) {
      return res.status(400).json({ 
        message: 'Either corrective actions must exist, or you must mark "No corrective action required" with justification' 
      })
    }

    if (no_action_required && !no_action_justification?.trim()) {
      return res.status(400).json({ 
        message: 'Justification is required when marking "No corrective action required"' 
      })
    }

    // Validation: evidence required unless waived
    if (!evidence_attached && !waived) {
      return res.status(400).json({ 
        message: 'Evidence is required. Attach evidence or mark as waived with a reason.' 
      })
    }

    if (waived && !waiver_reason?.trim()) {
      return res.status(400).json({ 
        message: 'Waiver reason is required when marking evidence as waived' 
      })
    }

      // Get user info for attestation
      const { data: userData } = await supabase
        .from('users')
        .select('full_name, role, email')
        .eq('id', userId)
        .single()

    // Create attestation atomically as part of closure
    const { data: attestation, error: attestationError } = await supabase
      .from('job_signoffs')
      .insert({
        job_id: work_record_id,
        signoff_type: 'incident_closure',
        status: 'signed',
        signed_by: userId,
        signed_at: new Date().toISOString(),
        comments: `Incident closure attestation: ${closure_summary}`,
      })
      .select()
      .single()

    if (attestationError || !attestation) {
      console.error('Failed to create attestation:', attestationError)
      return res.status(500).json({ message: 'Failed to create attestation' })
    }

    // Write incident.closed ledger entry
    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName: 'incident.closed',
      targetType: 'job',
      targetId: work_record_id,
      metadata: {
        closure_summary,
        root_cause,
        evidence_attached,
        waived: waived || false,
        waiver_reason: waived ? (waiver_reason || null) : null,
        no_action_required: no_action_required || false,
        no_action_justification: no_action_required ? (no_action_justification || null) : null,
        corrective_action_count: correctiveActions?.length || 0,
        attestation_id: attestation.id,
        ledger_entry_ids: ledger_entry_ids || [],
        summary: `Incident closed: ${closure_summary}`,
      },
    })

    // Write attestation.created ledger entry
    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName: 'attestation.created',
      targetType: 'system',
      targetId: attestation.id,
      metadata: {
        signoff_type: 'incident_closure',
        work_record_id,
        signer_name: userData?.full_name || 'Unknown',
        signer_role: userData?.role || 'Unknown',
        summary: `Incident closure attestation created`,
      },
    })

    res.json({ 
      success: true,
      message: 'Incident closed successfully',
      attestation_id: attestation.id,
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to close incident',
      internalMessage: err?.message || String(err),
      code: 'CLOSE_INCIDENT_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'CLOSE_INCIDENT_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/incidents/close')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/access/revoke
// Revokes access for a user (disable, downgrade role, or revoke sessions)
auditRouter.post('/access/revoke', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user

    // Check user role - only admin/owner can revoke
    const { data: currentUser } = await supabase
      .from('users')
      .select('role')
      .eq('id', userId)
      .single()

    if (!currentUser || (currentUser.role !== 'admin' && currentUser.role !== 'owner')) {
      return res.status(403).json({ 
        message: 'Only administrators and owners can revoke access',
        code: 'AUTH_ROLE_FORBIDDEN',
      })
    }

    const { target_user_id, action_type, reason, new_role } = req.body

    if (!target_user_id || !action_type || !reason) {
      return res.status(400).json({ 
        message: 'target_user_id, action_type, and reason are required' 
      })
    }

    // Cannot revoke own access
    if (target_user_id === userId) {
      return res.status(400).json({ 
        message: 'You cannot revoke your own access' 
      })
    }

    // Verify target user exists and belongs to organization
    const { data: targetUser, error: targetUserError } = await supabase
      .from('users')
      .select('id, email, full_name, role')
      .eq('id', target_user_id)
      .eq('organization_id', organization_id)
      .single()

    if (targetUserError || !targetUser) {
      return res.status(404).json({ message: 'Target user not found' })
    }

    // Cannot revoke executive access (they're read-only by design)
    if (targetUser.role === 'executive') {
      return res.status(403).json({ 
        message: 'Cannot revoke executive access - executives are read-only by design' 
      })
    }

    const priorRole = targetUser.role
    let newRole = priorRole
    let disabled = false
    let sessionsRevoked = false

    // Perform the action
    if (action_type === 'disable_user') {
      // Update user to disabled (you may need to add a disabled field to users table)
      // For now, we'll downgrade to a disabled role or add a flag
      const { error: updateError } = await supabase
        .from('users')
        .update({ role: 'member' }) // Downgrade as proxy for disabled
        .eq('id', target_user_id)
      
      if (updateError) {
        console.error('Failed to disable user:', updateError)
        return res.status(500).json({ message: 'Failed to disable user' })
      }
      disabled = true
      newRole = 'member'
    } else if (action_type === 'downgrade_role') {
      if (!new_role) {
        return res.status(400).json({ message: 'new_role is required for downgrade' })
      }
      const { error: updateError } = await supabase
        .from('users')
        .update({ role: new_role })
        .eq('id', target_user_id)
      
      if (updateError) {
        console.error('Failed to downgrade role:', updateError)
        return res.status(500).json({ message: 'Failed to downgrade role' })
      }
      newRole = new_role
    } else if (action_type === 'revoke_sessions') {
      // Session revocation would require Supabase Auth Admin API
      // For now, we'll just log it
      sessionsRevoked = true
    }

    // Write ledger entry
    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName: 'access.revoked',
      targetType: 'system',
      targetId: target_user_id,
      metadata: {
        target_user_id,
        target_user_email: targetUser.email,
        prior_role: priorRole,
        new_role: newRole,
        disabled,
        sessions_revoked: sessionsRevoked,
        action_type,
        reason,
        summary: `Access revoked: ${action_type} - ${reason}`,
      },
    })

    res.json({ 
      success: true,
      message: 'Access revoked successfully',
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to revoke access',
      internalMessage: err?.message || String(err),
      code: 'REVOKE_ACCESS_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'REVOKE_ACCESS_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/access/revoke')
    res.status(500).json(errorResponse)
  }
})

// POST /api/audit/access/flag-suspicious
// Flags suspicious access activity and optionally opens a security incident
auditRouter.post('/access/flag-suspicious', authenticate as unknown as express.RequestHandler, async (req: express.Request, res: express.Response) => {
  const authReq = req as AuthenticatedRequest & RequestWithId
  const requestId = authReq.requestId || 'unknown'
  
  try {
    const { organization_id, id: userId } = authReq.user
    const { target_user_id, login_event_id, reason, notes, severity, open_incident } = req.body

    if (!target_user_id || !reason) {
      return res.status(400).json({ 
        message: 'target_user_id and reason are required' 
      })
    }

    if (reason === 'other' && !notes?.trim()) {
      return res.status(400).json({ 
        message: 'Notes are required when reason is "other"' 
      })
    }

    // Verify target user exists
    const { data: targetUser } = await supabase
      .from('users')
      .select('id, email, full_name')
      .eq('id', target_user_id)
      .eq('organization_id', organization_id)
      .single()

    if (!targetUser) {
      return res.status(404).json({ message: 'Target user not found' })
    }

    // Write ledger entry
    await recordAuditLog({
      organizationId: organization_id,
      actorId: userId,
      eventName: 'security.suspicious_access.flagged',
      targetType: 'system',
      targetId: target_user_id,
      metadata: {
        target_user_id,
        target_user_email: targetUser.email,
        login_event_id: login_event_id || null,
        reason,
        notes: notes || null,
        severity: severity || 'material',
        open_incident: open_incident !== false, // Default true
        summary: `Suspicious access flagged: ${reason}`,
      },
    })

    // If open_incident is true, create an incident marker
    if (open_incident !== false) {
      // Create a security incident event that will appear in Incident Review
      await recordAuditLog({
        organizationId: organization_id,
        actorId: userId,
        eventName: 'security.incident.opened',
        targetType: 'system',
        targetId: target_user_id,
        metadata: {
          incident_type: 'suspicious_access',
          target_user_id,
          reason,
          notes: notes || null,
          severity: severity || 'material',
          summary: `Security incident opened: Suspicious access - ${reason}`,
        },
      })
    }

    res.json({ 
      success: true,
      message: 'Suspicious access flagged successfully',
      incident_opened: open_incident !== false,
    })
  } catch (err: any) {
    const { response: errorResponse, errorId } = createErrorResponse({
      message: 'Failed to flag suspicious access',
      internalMessage: err?.message || String(err),
      code: 'FLAG_SUSPICIOUS_ERROR',
      requestId,
      statusCode: 500,
    })
    res.setHeader('X-Error-ID', errorId)
    logErrorForSupport(500, 'FLAG_SUSPICIOUS_ERROR', requestId, authReq.user?.organization_id, errorResponse.message, errorResponse.internal_message, errorResponse.category, errorResponse.severity, '/api/audit/access/flag-suspicious')
    res.status(500).json(errorResponse)
  }
})
